- company: Mochi
  roles:
    - role: Co-Founder / Platform Engineer
      date: Dec 2022 - Present
      tools: Bash, Nix, SQLite, InfluxDB, Ansible, Terraform, Kubernetes, Cloud-Init
      # details: Self-hosted, independent network and infrastructure service provider for the Cardano blockchain network and associated ecosystem projects.

      details: |
        - Built the forge-manager application and Kubernetes Helm charts to enable fully automated, highly-available Cardano node deployments, eliminating manual coordination and supporting continuous operation across all nodes.
        - Authored comprehensive documentation for the forge-manager application, including functional and non-functional requirements, system architecture, and operational workflows.
        - Migrated infrastructure to Talos Linux, creating a fully declarative provisioning system that supports infrastructure-as-code.  
        - Implemented CI/CD pipelines with automated validation, reducing setup and upgrade times from 3+ hours to under 15 minutes with 100% successful deployments.
        - Implemented real-time monitoring and alerting with Grafana and Prometheus, cutting incident response time by ~60%.

- company: myKaarma
  page: 1
  roles:
    - role: Data Engineer (Cloud)
      tools: Python, SQL, Flink, Kafka, PySpark, AirFlow, Redshift, Lambda, Iceberg
      date: Jul 2023 - Jan 2024
      # details: Data Engineer at an automotive PaaS company, transitioning the company's data warehouse architecture to a modern lakehouse aimed at scalability, reliability and real-time, self-service analytics.

      details: |
        - Designed and contributed to a cloud data lakehouse architecture on AWS to centralize and scale analytics and reporting.
        - Built and maintained ETL/ELT pipelines using Python, Apache Airflow, AWS S3, AWS Glue and Redshift to ingest, transform and store cleaned event and transactional data.
        - Automated scheduled customer report generation and delivery using AWS Step Functions and Lambda with SLA monitoring and alerting.
        - Delivered a PoC batch processing pipeline using Airflow + PySpark that reduced message data processing time by ~70% compared to a stored-procedure based approach; validated performance and reliability metrics before handoff.

    - role: Data Engineer (Analytics)
      date: Feb 2022 - Jul 2023
      tools: Python, SQL, Power BI, Looker Studio, Airflow, PySpark, S3, Iceberg
      # details: Data Analyst tasked with requirements gathering, report generation and automation for business clients and internal stakeholders.

      details: |
        - Collaborated with external stakeholders to capture reporting requirements and translate them into actionable technical specifications for the data team.
        - Developed stored procedures for the reporting warehouse, optimizing several with indexing strategies to achieve up to 50% reduction in query execution time.
        - Integrated multiple operational and external data sources into Power BI, enabling standardized dashboards that reduced manual reporting workload for the analytics team.
        - Partnered with engineers to improve data quality checks and streamline ETL processes feeding the reporting warehouse.


# - company: Earlier Roles
#   roles:
#     - role: Software Engineer
#       date: 2016 - 2019
#
#       details: |
#         - Front-end and product experience (web & mobile) that complement full-stack pipeline delivery.

# - company: Urban Shelter Technologies
#   roles:
#     - role: Software Engineer
#       date: Jun 2018 - Jul 2019
#       tools: JavaScript, React, Firebase
#
#       details: |
#         - Developed a prototype web-interface in React for the company's house listing platform.
#         - Implemented user authentication and SSO using Firebase authentication.
#
# - company: BlueFire Technologies Inc.
#   roles:
#     - role: Software Engineer
#       date: Sep 2016 - Aug 2017
#       tools: JavaScript, React, Firebase
#
#       details: |
#         - Developed and deployed the front-end infrastructure for a Canadian food-delivery platform, on both web and Android.
#         - *Reduced data consumption on back-end requests by 65%* through front-end payload optimization.
